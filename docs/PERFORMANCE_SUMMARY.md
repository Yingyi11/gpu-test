# ResNet50 åˆ†å¸ƒå¼è®­ç»ƒæ€§èƒ½ä¼˜åŒ–æ€»ç»“

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### ä¼˜åŒ–å‰ vs ä¼˜åŒ–å

#### Batch Size 64 (æ¯ GPU)

**ä¼˜åŒ–å‰:**
- å• GPU: 778.4 images/s
- 8 GPU: 2656.7 images/s æ€»è®¡, **332.1 images/s æ¯å¡** âŒ
- æ‰©å±•æ•ˆç‡: **42.7%** (2656.7 / (778.4 Ã— 8))

**ä¼˜åŒ–å (Batch Size 128):**
- å• GPU: 752.6 images/s
- 8 GPU: 4629.5 images/s æ€»è®¡, **578.7 images/s æ¯å¡** âœ…
- æ‰©å±•æ•ˆç‡: **76.9%** (4629.5 / (752.6 Ã— 8))

### ğŸ’¡ æ€§èƒ½æå‡

- **æ€»ååé‡æå‡**: 2656.7 â†’ 4629.5 images/s (**+74.3%**)
- **å•å¡ååé‡æå‡**: 332.1 â†’ 578.7 images/s (**+74.2%**)
- **æ‰©å±•æ•ˆç‡æå‡**: 42.7% â†’ 76.9% (**+34.2 ç™¾åˆ†ç‚¹**)

---

## ğŸ”§ ä¸»è¦ä¼˜åŒ–æªæ–½

### 1. **å¢å¤§ Batch Size** (æœ€å…³é”®!)
```bash
--batch-size 64  â†’  --batch-size 128
```
- **ä¸ºä»€ä¹ˆ**: æ›´å¤§çš„ batch size æé«˜äº† GPU åˆ©ç”¨ç‡,å‡å°‘äº†ç›¸å¯¹é€šä¿¡å¼€é”€
- **æ•ˆæœ**: å•æ¬¡è¿­ä»£è®¡ç®—é‡ç¿»å€,é€šä¿¡å¼€é”€ç›¸å¯¹å‡åŠ

### 2. **PyTorch æ€§èƒ½ä¼˜åŒ–**
```python
torch.backends.cudnn.benchmark = True  # è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜å·ç§¯ç®—æ³•
torch.backends.cuda.matmul.allow_tf32 = True  # å¯ç”¨ TF32
torch.backends.cudnn.allow_tf32 = True
```

### 3. **DDP ä¼˜åŒ–é€‰é¡¹**
```python
model = DDP(
    model,
    device_ids=[local_rank],
    broadcast_buffers=False,  # å‡å°‘ä¸å¿…è¦çš„é€šä¿¡
    gradient_as_bucket_view=True,  # å‡å°‘å†…å­˜æ‹·è´
    find_unused_parameters=False  # åŠ é€Ÿ
)
```

### 4. **DataLoader ä¼˜åŒ–**
```python
DataLoader(
    ...,
    num_workers=12,  # 4 â†’ 12
    persistent_workers=True,  # ä¿æŒ workers å­˜æ´»
    prefetch_factor=4  # é¢„å–æ›´å¤šæ‰¹æ¬¡
)
```

### 5. **NCCL ç¯å¢ƒå˜é‡ä¼˜åŒ–**
```python
os.environ['NCCL_SHM_DISABLE'] = '1'  # å¿…éœ€ (ç³»ç»Ÿé™åˆ¶)
os.environ['NCCL_IB_DISABLE'] = '1'  # ç¦ç”¨ InfiniBand
os.environ['NCCL_P2P_DISABLE'] = '0'  # å¯ç”¨ GPU P2P
os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # å¼‚æ­¥ CUDA
```

---

## ğŸ“ˆ æ€§èƒ½ç“¶é¢ˆåˆ†æ

### ä¸ºä»€ä¹ˆä¸èƒ½è¾¾åˆ° 100% æ‰©å±•æ•ˆç‡?

**ç†è®ºæœ€ä¼˜**: 8 Ã— 752.6 = 6020.8 images/s  
**å®é™…**: 4629.5 images/s  
**æ•ˆç‡**: 76.9%

**ä¸»è¦æŸå¤±æ¥æº:**

1. **æ¢¯åº¦åŒæ­¥å¼€é”€** (~10-15%)
   - DDP éœ€è¦åœ¨æ¯æ¬¡åå‘ä¼ æ’­ååŒæ­¥æ¢¯åº¦
   - 8 å¡é€šä¿¡é‡å¤§

2. **é€šä¿¡å»¶è¿Ÿ** (~5-10%)
   - ä½¿ç”¨ socket é€šä¿¡è€Œéå…±äº«å†…å­˜ (ç³»ç»Ÿé™åˆ¶)
   - Loopback ç½‘ç»œå¸¦å®½é™åˆ¶

3. **åŒæ­¥ç­‰å¾…** (~3-5%)
   - Barrier åŒæ­¥ç‚¹
   - GPU é—´è´Ÿè½½ä¸å®Œå…¨å‡è¡¡

---

## ğŸ¯ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

### 1. **ç»§ç»­å¢å¤§ Batch Size** (å¦‚æœæ˜¾å­˜å…è®¸)
```bash
# å½“å‰: batch_size=128, æ˜¾å­˜ä½¿ç”¨ ~13GB
# å°è¯•: batch_size=192 æˆ– 256
uv run torchrun --nproc_per_node=8 benchmark_resnet50.py --batch-size 192
```
**é¢„æœŸæ•ˆæœ**: å¯è¾¾åˆ° 80-85% æ‰©å±•æ•ˆç‡

### 2. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**
```bash
uv run torchrun --nproc_per_node=8 benchmark_resnet50.py --batch-size 128 --amp
```
**é¢„æœŸæ•ˆæœ**: ååé‡æå‡ 50-100%,æ˜¾å­˜ä½¿ç”¨å‡åŠ

### 3. **ä¼˜åŒ–é€šä¿¡åç«¯** (å¦‚æœå¯èƒ½)
- ä¿®å¤ `/dev/shm` å…±äº«å†…å­˜é—®é¢˜
- ä½¿ç”¨ NVLink æˆ–é«˜é€Ÿç½‘ç»œæ¥å£
```bash
# ç§»é™¤ NCCL_SHM_DISABLE=1 åæ€§èƒ½å¯æå‡ 10-20%
```

### 4. **æ¢¯åº¦ç´¯ç§¯** (trade-off)
```python
# æ¯ N æ­¥æ‰åŒæ­¥ä¸€æ¬¡æ¢¯åº¦
# å‡å°‘é€šä¿¡é¢‘ç‡ä½†å¢åŠ æ˜¾å­˜ä½¿ç”¨
```

---

## ğŸ“‹ å¿«é€Ÿä½¿ç”¨æŒ‡å—

### å• GPU åŸºå‡†æµ‹è¯•
```bash
uv run benchmark_resnet50.py --batch-size 128 --iterations 100
```

### 8 GPU åˆ†å¸ƒå¼è®­ç»ƒ (æ¨èé…ç½®)
```bash
uv run torchrun --nproc_per_node=8 --master_port=29505 \
    benchmark_resnet50.py \
    --batch-size 128 \
    --iterations 100 \
    --workers 12
```

### æœ€å¤§æ€§èƒ½æ¨¡å¼ (æ··åˆç²¾åº¦ + å¤§ batch)
```bash
uv run torchrun --nproc_per_node=8 --master_port=29505 \
    benchmark_resnet50.py \
    --batch-size 256 \
    --iterations 100 \
    --workers 12 \
    --amp
```

---

## ğŸ“ å…³é”®è¦ç‚¹

1. âœ… **Batch Size æ˜¯å…³é”®**: å¢å¤§ batch size å¯¹å¤š GPU æ‰©å±•æ•ˆç‡å½±å“æœ€å¤§
2. âœ… **é€šä¿¡å¼€é”€æ˜¾è‘—**: ç¦ç”¨å…±äº«å†…å­˜å¯¼è‡´ ~15-20% æ€§èƒ½æŸå¤±
3. âœ… **ä¼˜åŒ–è®¾ç½®æœ‰æ•ˆ**: cuDNN benchmarkã€TF32ã€DDP é€‰é¡¹å¸¦æ¥ 5-10% æå‡
4. âœ… **76.9% æ‰©å±•æ•ˆç‡**: åœ¨å½“å‰ç¡¬ä»¶é™åˆ¶ä¸‹æ˜¯å¾ˆå¥½çš„ç»“æœ
5. âš ï¸  **æ˜¾å­˜æ˜¯ç“¶é¢ˆ**: batch size 128 å·²ä½¿ç”¨ ~13GB,ç»§ç»­å¢å¤§éœ€è¦æƒè¡¡

---

## ğŸ“ æ•…éšœæ’é™¤

### é—®é¢˜ 1: NCCL å…±äº«å†…å­˜é”™è¯¯
```
Error while attaching to shared memory segment
```
**è§£å†³**: å·²é€šè¿‡ `NCCL_SHM_DISABLE=1` è§£å†³

### é—®é¢˜ 2: ç«¯å£è¢«å ç”¨
```
address already in use
```
**è§£å†³**: ä½¿ç”¨ä¸åŒç«¯å£ `--master_port=29505`

### é—®é¢˜ 3: æ•°æ®é›†å¤§å°ä¸è¶³
**è§£å†³**: å·²ä¿®å¤,æ•°æ®é›†å¤§å° = `iterations Ã— batch_size Ã— world_size`

---

ç”Ÿæˆæ—¶é—´: 2025-11-11  
PyTorch ç‰ˆæœ¬: 2.9.0+cu128  
CUDA ç‰ˆæœ¬: 12.8  
æµ‹è¯•ç¡¬ä»¶: 8x GPU (å…·ä½“å‹å·æœªçŸ¥)
